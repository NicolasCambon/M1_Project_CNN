{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CONV_CAMBON_FIEVE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "R0ohKr6TMPu_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Projet 2 : Reconnaissance de chiffres manuscrits (MNIST)**\n",
        "\n",
        "**Nicolas Cambon et Justine Fiévé - Master 1 Sciences Cognitives (2019)**"
      ]
    },
    {
      "metadata": {
        "id": "badZFeYNNfiz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pour ce dernier projet, nous utilisons un réseau convolutionnel (CNN) permettant la classification d'images, et plus précisément d'images contenant un chiffre manuscrit (de 0 à 9, un chiffre par image). L'avantage du CNN est que son architecture permet de traiter des séries temporelles (ici, les nuances de gris de chaque image).\n",
        "\n",
        "Le but est donc que ce réseau arrive à identifier les différents chiffres manuscrits, en faisant le moins d'erreur possible. Pour cela, il aura à disposition 60 000 images lors de la phase d'apprentissage puis 10 000 images lors de la phase de test. On cherche également à savoir si la perte de précision du détail de la nuance de gris sur les pixels influence grandement la capacité du réseau à prédire le bon chiffre.\n",
        "\n",
        "Nous supposons alors que cette perte du détail de nuances de gris n'influence pas les capacités de réussite du réseau convolutionnel."
      ]
    },
    {
      "metadata": {
        "id": "82mWYy1z03aC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On commence donc par récupérer les données d'apprentissage et de test."
      ]
    },
    {
      "metadata": {
        "id": "C6B2tyHV0RGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm train_image_file.txt train_label_file.txt test_image_file.txt test_label_file.txt mnist.tgz\n",
        "wget http://pageperso.lif.univ-mrs.fr/~alexis.nasr/Ens/MASCO_Apprentissage_Automatique/mnist.tgz\n",
        "tar xvfz mnist.tgz\n",
        "ls data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_olsRxA1CeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On met ensuite en forme les données d'apprentissage. Pour cela, on transforme les listes de listes en tableau numpy 60000 x 28 x 28 x 1 pour les données d'apprentissage et 10000 x 28 x 28 x 1 pour les données de tests dans le but qu'elles puissent être prises en compte par Keras. \n",
        "\n",
        "Nous faisons également la mise en forme des labels d'apprentissage et de test en tableau numpy 60000 x 10 et 10000 x 10 respectivement. Pour chaque label, nous avons mis une liste de 10 éléments à la place d'un seul pour que Keras puisse comparer sa sortie, étant une liste de 10 éléments, à notre solution."
      ]
    },
    {
      "metadata": {
        "id": "ViHT3u4k1c5y",
        "colab_type": "code",
        "outputId": "a52d7394-33b0-4ea6-e452-879b25b9a1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def lecture_images(nomFichierImages):\n",
        "    print(\"lecture des donnees d'entrée depuis le fichier : \", nomFichierImages) # la fonction lecture-image essaie d'ouvrir le fichier, renvoyant une erreur si ce dernier n'exsite pas\n",
        "    try:\n",
        "        fichier = open(nomFichierImages,\"r\")\n",
        "    except IOError:\n",
        "        print(\"le fichier\",nomFichierLabels, \"n'existe pas\")\n",
        "        return None\n",
        "    fichier_entier = fichier.read() # on lit le fichier\n",
        "    fichier.close()   \n",
        "    files = fichier_entier.split(\" \") # on découpe les données du fichier par leur espace\n",
        "    for i in range (0,len(files)):\n",
        "      if files[i] == \"\\n0\": # pour toutes les données \"\\n0\", on les remplace par 0\n",
        "        files[i]=\"0\"\n",
        "    if files[-1] == \"\\n\": # si le dernier élément est un \\n, on l'enlève\n",
        "      files.pop(-1)\n",
        "    image_nuance=[]\n",
        "    full_images=[]\n",
        "    for i in range(1,len(files)+1): # pour tous les éléments de files \n",
        "      if i %(28*28) == 0 : # si le reste de l'élément par 784 est nul\n",
        "        full_images.append(files[i-1]) # on ajoute à la liste full_images le 784 ème pixel de l'image\n",
        "        image_nuance.append(full_images) # on introduit l'image dans la liste image_nuance créant une liste comportant la liste des pixels pour chaque image\n",
        "        full_images=[] # on remet à 0 la liste full_images\n",
        "      else:\n",
        "        full_images.append(files[i-1]) # on ajoute les éléments de l'image dans la liste full_images\n",
        "    k = len(image_nuance)\n",
        "    image_nuance = np.array(image_nuance) # transformation des données en tableau\n",
        "    image_nuance = image_nuance.reshape(k,28,28,1) # transformation en tableau k x 28 x 28 x 1\n",
        "    return(image_nuance) # on renvoie le tableau image_nuance\n",
        "      \n",
        "    \n",
        "    \n",
        "\n",
        "def lecture_labels(nomFichierLabels):\n",
        "    print(\"lecture des donnees de sortie depuis le fichier : \", nomFichierLabels)\n",
        "    try:\n",
        "        fichier = open(nomFichierLabels,\"r\")\n",
        "    except IOError:\n",
        "        print(\"le fichier\",nomFichierLabels, \"n'existe pas\")\n",
        "        return None\n",
        "    fichier_lab = fichier.read()\n",
        "    fichier.close()\n",
        "    lab = fichier_lab.split(\"\\n\") # on sépare les données par rapport au \\n\n",
        "    if len(lab[-1]) == 0 : # si le dernier élément est vide\n",
        "      lab.pop(-1) # on l'enlève\n",
        "    l = len(lab)\n",
        "    ly = []\n",
        "    for i in range(len(lab)): # création d'une liste de 10 éléments pour chaque label\n",
        "        v = [0] * 10\n",
        "        v[int(lab[i])] = 1\n",
        "        ly.append(v)\n",
        " \n",
        "    lab = np.array(ly)\n",
        "    lab=lab.reshape(l,10)\n",
        "    return(lab)\n",
        "    \n",
        "x_train = lecture_images('./data/train_image_file.txt')\n",
        "y_train = lecture_labels('./data/train_label_file.txt')\n",
        "\n",
        "print('x shape = ', x_train.shape)\n",
        "print('y shape = ', y_train.shape)\n",
        "\n",
        "x_test = lecture_images('./data/test_image_file.txt')\n",
        "y_test = lecture_labels('./data/test_label_file.txt')\n",
        "\n",
        "print('x shape = ', x_test.shape)\n",
        "print('y shape = ', y_test.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lecture des donnees d'entrée depuis le fichier :  ./data/train_image_file.txt\n",
            "lecture des donnees de sortie depuis le fichier :  ./data/train_label_file.txt\n",
            "x shape =  (60000, 28, 28, 1)\n",
            "y shape =  (60000, 10)\n",
            "lecture des donnees d'entrée depuis le fichier :  ./data/test_image_file.txt\n",
            "lecture des donnees de sortie depuis le fichier :  ./data/test_label_file.txt\n",
            "x shape =  (10000, 28, 28, 1)\n",
            "y shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWsQgvNTKrw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Construction et apprentissage du modèle.\n",
        "\n",
        "Ici, on créé le réseau convolutionnel avec ses différentes couches de pooling étant : \n",
        "          - Sequential\n",
        "          - Conv2D\n",
        "          - MaxPooling2D\n",
        "          - Conv2D\n",
        "          - MaxPooling2D\n",
        "          - Dropout\n",
        "          - Flatten\n",
        "          - Dense\n",
        "\n",
        "Le réseau reçoit en entrée (x) les différentes images de 28 x 28 pixels. Elles sont sous la forme de 784 séquences de nombres compris entre 0 (blanc) et 255 (noir) représentant les nuances de gris. Ces nuances de gris illustrent un chiffre.\n",
        "\n",
        "Pour la sortie (y), le réseau reçoit la réponse et la compare avec sa prédiction (y'). Nous affichons pour l'apprentissage et les tests son taux de réussite en pourcentage ainsi que la focntion de perte."
      ]
    },
    {
      "metadata": {
        "id": "ov_pD_6An7Ah",
        "colab_type": "code",
        "outputId": "a9dbe1ee-2958-4ff6-b9dd-a9e29b6db685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "#model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test, y_test))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 1.6375 - acc: 0.8293 - val_loss: 0.1146 - val_acc: 0.9650\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 0.1340 - acc: 0.9608 - val_loss: 0.0716 - val_acc: 0.9786\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0900 - acc: 0.9733 - val_loss: 0.0502 - val_acc: 0.9850\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0705 - acc: 0.9780 - val_loss: 0.0471 - val_acc: 0.9853\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0598 - acc: 0.9819 - val_loss: 0.0387 - val_acc: 0.9876\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0538 - acc: 0.9833 - val_loss: 0.0365 - val_acc: 0.9875\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0469 - acc: 0.9852 - val_loss: 0.0350 - val_acc: 0.9887\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0434 - acc: 0.9866 - val_loss: 0.0357 - val_acc: 0.9889\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0397 - acc: 0.9871 - val_loss: 0.0329 - val_acc: 0.9896\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.0319 - val_acc: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76bb2e1f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "1hq8yh12UK8Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On peut observer que dès la première Epoch, le réseau a environ 83 % de réussite pour les données d'apprentissage et environ 97 % pour les données de tests. Au bout de 10 Epoch, il atteint, en moyenne, 98 % pour l'apprentissage et le test indiquant que le réseau a de bonnes performances prédictives. La fonction de perte, quant à elle, diminue."
      ]
    },
    {
      "metadata": {
        "id": "jIeCJzhmUaCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Après l'avoir testé, nous essayons de voir si les séquences de nuances de gris sont importantes pour que le réseau réponde correctement. Nous avons donc créer une fonction lecture_images_col qui transforme les images \"en noir et blanc\". En d'autres termes, tous les chiffres différents de 0 sont changés en 1 (les 0 restent tels quels), il n'y a plus de nuances de gris. "
      ]
    },
    {
      "metadata": {
        "id": "Uz1ebAO8WnJn",
        "colab_type": "code",
        "outputId": "4d4db123-885f-4c1e-ebce-af03d24f37c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "def lecture_images_col(nomFichierImages):\n",
        "    print(\"lecture des donnees d'entrée depuis le fichier : \", nomFichierImages)\n",
        "    try:\n",
        "        fichier = open(nomFichierImages,\"r\")\n",
        "    except IOError:\n",
        "        print(\"le fichier\",nomFichierLabels, \"n'existe pas\")\n",
        "        return None\n",
        "    fichier_entier = fichier.read()\n",
        "    fichier.close()  \n",
        "    files = fichier_entier.split(\" \")\n",
        "    for i in range (0,len(files)):\n",
        "      if files[i] == \"\\n0\":\n",
        "        files[i]=\"0\"\n",
        "    if files[-1] == \"\\n\":\n",
        "      files.pop(-1)\n",
        "    image_nuance=[]\n",
        "    full_images=[]\n",
        "    for i in range(1,len(files)+1):\n",
        "      if i %(28*28) == 0 :\n",
        "        if int(files[i-1]) == 0: # si l'élement est égale à 0, ajout de 0 dans full_images\n",
        "          full_images.append(0)\n",
        "          image_nuance.append(full_images)\n",
        "          full_images=[]\n",
        "        else:  # sinon, l'élement est égale à 1\n",
        "          full_images.append(1)\n",
        "          image_nuance.append(full_images)\n",
        "          full_images=[]\n",
        "      else:\n",
        "        if int(files[i-1]) == 0:\n",
        "          full_images.append(0)\n",
        "        else :\n",
        "          full_images.append(1)\n",
        "    k = len(image_nuance)\n",
        "    image_nuance = np.array(image_nuance)\n",
        "    image_nuance = image_nuance.reshape(k,28,28,1)\n",
        "    return(image_nuance)\n",
        "  \n",
        "x_train_col = lecture_images_col('./data/train_image_file.txt') \n",
        "print('x shape = ', x_train_col.shape)\n",
        "\n",
        "x_test_col = lecture_images_col('./data/test_image_file.txt')\n",
        "print('x shape = ', x_test_col.shape)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lecture des donnees d'entrée depuis le fichier :  ./data/train_image_file.txt\n",
            "x shape =  (60000, 28, 28, 1)\n",
            "lecture des donnees d'entrée depuis le fichier :  ./data/test_image_file.txt\n",
            "x shape =  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ogv51Ph8WnYt",
        "colab_type": "code",
        "outputId": "aa94187b-c615-42ec-93f1-5a30a62801c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train_col, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test_col, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 46s 761us/step - loss: 0.5019 - acc: 0.8415 - val_loss: 0.1163 - val_acc: 0.9668\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 45s 753us/step - loss: 0.1296 - acc: 0.9603 - val_loss: 0.0755 - val_acc: 0.9766\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 45s 758us/step - loss: 0.1023 - acc: 0.9681 - val_loss: 0.0646 - val_acc: 0.9803\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 46s 759us/step - loss: 0.0902 - acc: 0.9718 - val_loss: 0.0611 - val_acc: 0.9809\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 45s 755us/step - loss: 0.0818 - acc: 0.9747 - val_loss: 0.0558 - val_acc: 0.9828\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 46s 759us/step - loss: 0.0756 - acc: 0.9761 - val_loss: 0.0533 - val_acc: 0.9837\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 46s 759us/step - loss: 0.0714 - acc: 0.9784 - val_loss: 0.0489 - val_acc: 0.9840\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 46s 763us/step - loss: 0.0676 - acc: 0.9782 - val_loss: 0.0478 - val_acc: 0.9854\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 45s 756us/step - loss: 0.0655 - acc: 0.9789 - val_loss: 0.0509 - val_acc: 0.9840\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 45s 756us/step - loss: 0.0627 - acc: 0.9806 - val_loss: 0.0462 - val_acc: 0.9854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76d06ce3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Z62rBWiVW2ZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Également, on peut observer que le réseau arrive à environ 98 % de réussite pour les données d'apprentissage et de tests au bout de 10 Epoch. La fonction de perte diminue au fur et à mesure des tests. On peut donc penser que les nuances de gris n'influencent pas l'apprentissage du réseau convolutionnel, comme nous l'avons supposé en introduction."
      ]
    },
    {
      "metadata": {
        "id": "E2fcmR3IXcFv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Par la suite, nous avons voulu tester si le réseau était sensible à la translation ou à la rotation des images. Nous avons donc, pour commencer, essayer la translation des images."
      ]
    },
    {
      "metadata": {
        "id": "5v2-T9w4wf5X",
        "colab_type": "code",
        "outputId": "f0a7e992-ddc1-46d3-95af-e7ac1f429dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "def lecture_images_translation(nomFichierImages):\n",
        "    print(\"lecture des donnees d'entrée depuis le fichier : \", nomFichierImages)\n",
        "    try:\n",
        "        fichier = open(nomFichierImages,\"r\")\n",
        "    except IOError:\n",
        "        print(\"le fichier\",nomFichierLabels, \"n'existe pas\")\n",
        "        return None\n",
        "    fichier_entier = fichier.read()\n",
        "    fichier.close()  \n",
        "    files = fichier_entier.split(\" \")\n",
        "    for i in range (0,len(files)):\n",
        "      if files[i] == \"\\n0\":\n",
        "        files[i]=\"0\"\n",
        "    if files[-1] == \"\\n\":\n",
        "      files.pop(-1)\n",
        "    image_nuance=[]\n",
        "    full_images=[]\n",
        "    for i in range(1,len(files)+1):\n",
        "      if i %(28*28) == 0 : \n",
        "        full_images.insert(0,files[i-1]) # pour chaque ligne de pixels, on inverse leur position\n",
        "        image_nuance.append(full_images)\n",
        "        full_images=[]\n",
        "      else:\n",
        "        full_images.insert(0,files[i-1])\n",
        "    k = len(image_nuance)\n",
        "    image_nuance = np.array(image_nuance)\n",
        "    image_nuance = image_nuance.reshape(k,28,28,1)\n",
        "    return(image_nuance)\n",
        "  \n",
        "x_train_trans = lecture_images_translation('./data/train_image_file.txt') \n",
        "print('x shape = ', x_train_trans.shape)\n",
        "\n",
        "x_test_trans = lecture_images_translation('./data/test_image_file.txt')\n",
        "print('x shape = ', x_test_trans.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lecture des donnees d'entrée depuis le fichier :  ./data/train_image_file.txt\n",
            "x shape =  (60000, 28, 28, 1)\n",
            "lecture des donnees d'entrée depuis le fichier :  ./data/test_image_file.txt\n",
            "x shape =  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rr80TPwHyJWK",
        "colab_type": "code",
        "outputId": "7cef3607-7af7-4bdb-97c8-7b192b5acbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train_trans, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test_trans, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 8.8732 - acc: 0.4485 - val_loss: 8.0352 - val_acc: 0.5011\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 8.1141 - acc: 0.4958 - val_loss: 7.5280 - val_acc: 0.5324\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 7.5708 - acc: 0.5295 - val_loss: 6.8939 - val_acc: 0.5716\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 7.1596 - acc: 0.5552 - val_loss: 6.7987 - val_acc: 0.5777\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 7.0024 - acc: 0.5649 - val_loss: 6.7193 - val_acc: 0.5829\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 6.9332 - acc: 0.5694 - val_loss: 6.6421 - val_acc: 0.5878\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 6.8787 - acc: 0.5727 - val_loss: 6.6564 - val_acc: 0.5865\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 65s 1ms/step - loss: 6.8564 - acc: 0.5743 - val_loss: 6.6217 - val_acc: 0.5888\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 6.8374 - acc: 0.5752 - val_loss: 6.6218 - val_acc: 0.5890\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 6.8140 - acc: 0.5768 - val_loss: 6.5918 - val_acc: 0.5908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76d0f04748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "qvfreP-SXsgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On observe que dans ce cas-là, le réseau a un taux de réussite d'environ 60 % pour les données d'apprentissage et de tests et que la fonction de perte est plus élevée comparés aux tests précédents. La translation impacte les capacités de prédiction du réseau."
      ]
    },
    {
      "metadata": {
        "id": "T9H4_0GAX9on",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nous testons ensuite la rotation des images."
      ]
    },
    {
      "metadata": {
        "id": "MJetJe2q2RFH",
        "colab_type": "code",
        "outputId": "508c40f5-ab7b-45f2-b5c5-19f1d92544d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "def lecture_images_inversion(nomFichierImages):\n",
        "    print(\"lecture des donnees d'entrée depuis le fichier : \", nomFichierImages)\n",
        "    try:\n",
        "        fichier = open(nomFichierImages,\"r\")\n",
        "    except IOError:\n",
        "        print(\"le fichier\",nomFichierLabels, \"n'existe pas\")\n",
        "        return None\n",
        "    fichier_entier = fichier.read()\n",
        "    fichier.close()  \n",
        "    files = fichier_entier.split(\" \")\n",
        "    for i in range (0,len(files)):\n",
        "      if files[i] == \"\\n0\":\n",
        "        files[i]=\"0\"\n",
        "    if files[-1] == \"\\n\":\n",
        "      files.pop(-1)\n",
        "    image_nuance=[]\n",
        "    full_images=[]\n",
        "    for i in range(1,len(files)+1):\n",
        "      if i %(28*28) == 0 :\n",
        "        full_images.append(files[i-1])\n",
        "        image_nuance.insert(0,full_images) # pour chaque colonne de pixels, on inverse leur position\n",
        "        full_images=[]\n",
        "      else:\n",
        "        full_images.append(files[i-1])\n",
        "    k = len(image_nuance)\n",
        "    image_nuance = np.array(image_nuance)\n",
        "    image_nuance = image_nuance.reshape(k,28,28,1)\n",
        "    return(image_nuance)\n",
        "  \n",
        "x_train_inv = lecture_images_inversion('./data/train_image_file.txt') \n",
        "print('x shape = ', x_train_inv.shape)\n",
        "\n",
        "x_test_inv = lecture_images_inversion('./data/test_image_file.txt')\n",
        "print('x shape = ', x_test_inv.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lecture des donnees d'entrée depuis le fichier :  ./data/train_image_file.txt\n",
            "x shape =  (60000, 28, 28, 1)\n",
            "lecture des donnees d'entrée depuis le fichier :  ./data/test_image_file.txt\n",
            "x shape =  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pCVEhif52RWO",
        "colab_type": "code",
        "outputId": "142ec832-0074-4558-c59d-0f706c41a413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train_inv, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test_inv, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5336 - acc: 0.0975 - val_loss: 14.5069 - val_acc: 0.0994\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5397 - acc: 0.0972 - val_loss: 14.5530 - val_acc: 0.0968\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5422 - acc: 0.0972 - val_loss: 14.5701 - val_acc: 0.0958\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5254 - acc: 0.0983 - val_loss: 14.5130 - val_acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5340 - acc: 0.0978 - val_loss: 14.5506 - val_acc: 0.0969\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5461 - acc: 0.0974 - val_loss: 14.5239 - val_acc: 0.0988\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5395 - acc: 0.0979 - val_loss: 14.5320 - val_acc: 0.0983\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5360 - acc: 0.0979 - val_loss: 14.5473 - val_acc: 0.0974\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5473 - acc: 0.0974 - val_loss: 14.5453 - val_acc: 0.0975\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 64s 1ms/step - loss: 14.5456 - acc: 0.0976 - val_loss: 14.5482 - val_acc: 0.0974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76b66710f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "6Sj80REOYCF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dans le cas de la rotation, le réseau n'arrive pas du tout à identifer les chiffres manuscrits. En effet, il a un taux de réussite de seulement 10 % pour les données d'apprentissage et de tests, on peut dire qu'il répond aléatoirement. Ainsi, la rotation des données annihile complètement les capacités de prédiction du réseau."
      ]
    },
    {
      "metadata": {
        "id": "GVAgJaUUYj8g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Conclusion :**\n",
        "\n",
        "**D'après ces observations, nous pouvons dire que lorsque nous modifions seulement des détails dans les données (ici, les nuances de gris), le réseau convolutionnel garde intacte ses capacités de prédiction (environ 98 % de réussite pour les données d'apprentissage et de tests).**\n",
        "\n",
        "**Cependant, lorsque nous changeons leur nature, les données deviennent plus difficiles à être traitées par le réseau, diminuant alors grandement ses capacités de prédiction (60 % de réussite pour la translation et 10 % de réussite pour la rotation pour les données d'apprentissage et de test). Le réseau n'est donc pas adapté pour traiter cette configuration.**"
      ]
    }
  ]
}